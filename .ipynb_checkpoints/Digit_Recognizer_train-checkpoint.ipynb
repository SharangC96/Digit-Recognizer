{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#function which one hot encodes a numpy array\n",
    "def OneHotEncode(y):\n",
    "    size=y.shape[0]\n",
    "    temp=np.zeros([size,10])\n",
    "    for i in range(size):\n",
    "        temp[i][y[i]]=1\n",
    "    \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('train.csv')\n",
    "y_data=train_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data from pandas dataframe to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_data=OneHotEncode(y_data)\n",
    "X_data=train_data.iloc[:,1:].values\n",
    "X_data=np.reshape(X_data,[-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train data to create a local validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_data_train,X_data_test,y_data_train,y_data_test=train_test_split(X_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete arrays which are no longer required to free up RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_data,X_data,y_data,X_data_test,y_data_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define input queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1=tf.RandomShuffleQueue(capacity=800,min_after_dequeue=300,dtypes=tf.float32,shapes=[28,28,1],seed=6)\n",
    "q2=tf.RandomShuffleQueue(capacity=800,min_after_dequeue=300,dtypes=tf.float32,shapes=[10],seed=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define enqueue operation that is with what to populate above defined queues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enqueue_op1= q1.enqueue_many(vals=X_data_train)\n",
    "enqueue_op2= q2.enqueue_many(vals=y_data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add these queues to the TensorFlow queue Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numberOfThreads = 3\n",
    "qr1 = tf.train.QueueRunner(q1, [enqueue_op1] * numberOfThreads)\n",
    "qr2 = tf.train.QueueRunner(q2, [enqueue_op2] * numberOfThreads)\n",
    "\n",
    "tf.train.add_queue_runner(qr1)\n",
    "tf.train.add_queue_runner(qr2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to create Convolutional Layers and Fully Connected Layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function performs three things \n",
    "# 1) Convolution\n",
    "# 2) Relu activation of the convolved output\n",
    "# 3) Max Pooling of the output obtained after Relu Activation to reduce the size of the array\n",
    "# First Step:It performs 3-D convolution on the given array(X here) with a filter of mentioned size (filter_size here)\n",
    "#            and no_of_filters determines the no of output channels.\n",
    "# Second Step: Apply Relu actiavtion function on the above output \n",
    "# Third Step : Take Max pool(here 2X2 with strides of 2X2) of the output obtained from above.\n",
    "def ConvLayer(X,no_of_filters,filter_size):\n",
    "    in_channels=int(X.shape[3])\n",
    "    W=tf.get_variable(\"filter\",dtype=tf.float32,initializer=tf.random_normal([filter_size,filter_size,in_channels,no_of_filters]))\n",
    "    b=tf.get_variable(\"bias\",dtype=tf.float32,initializer=tf.random_normal([no_of_filters]))\n",
    "    \n",
    "    out=tf.nn.relu(tf.add(tf.nn.conv2d(input=X,filter=W,strides=[1,1,1,1],padding='SAME'),b))\n",
    "    pool=tf.nn.max_pool(value=out,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function creates a layer of a simple neural network\n",
    "# Function Arguments are\n",
    "# X:input data , out_layer: no of neurons in the hidden layer\n",
    "def FcLayer(X,out_layer):\n",
    "    in_layer=int(X.shape[1])\n",
    "    \n",
    "    W=tf.get_variable(\"Weights\",dtype=tf.float32,initializer=tf.random_normal([in_layer,out_layer],dtype=tf.float32))\n",
    "    b=tf.get_variable(\"Bias\",dtype=tf.float32,initializer=tf.random_normal([out_layer],dtype=tf.float32))\n",
    "    \n",
    "    out=tf.add(tf.matmul(X,W),b)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=200\n",
    "X=q1.dequeue_many(batch_size)\n",
    "y=q2.dequeue_many(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the complete CNN\n",
    "### Dropout has been employed on all the layers to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Conv_layer1\"):\n",
    "    out1=ConvLayer(X,32,5)\n",
    "    out1=tf.nn.dropout(out1,0.9)\n",
    "with tf.variable_scope(\"Conv_layer2\"):\n",
    "    out2=ConvLayer(out1,64,5)\n",
    "    out2=tf.nn.dropout(out2,0.8)\n",
    "with tf.variable_scope(\"Conv_layer3\"):\n",
    "    out3=ConvLayer(out2,128,2)\n",
    "    out3=tf.nn.dropout(out3,0.7)\n",
    "\n",
    "channels=int(out3.shape[3])\n",
    "length=int(out3.shape[2])\n",
    "breadth=int(out3.shape[1])\n",
    "\n",
    "out3=tf.reshape(out3,[-1,length*breadth*channels])\n",
    "\n",
    "with tf.variable_scope(\"Fc_layer1\"):\n",
    "    fc_out1=FcLayer(out3,3072)\n",
    "    fc_out1=tf.nn.relu(fc_out1)\n",
    "    fc_out1=tf.nn.dropout(fc_out1,0.7)\n",
    "\n",
    "with tf.variable_scope(\"Fc_layer2\"):\n",
    "    fc_out2=FcLayer(fc_out1,10)\n",
    "\n",
    "prediction=tf.arg_max(fc_out2,dimension=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function which is cross entropy here \n",
    "### Define the training step, AdamOptimizer with learning rate 1e-3 has been used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=fc_out2,labels=y))\n",
    "train_step=tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.arg_max(y,dimension=1),prediction),dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise all the variables and\n",
    "### Start the queue runners to begin filling queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess,coord=coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To load network weights from disk \n",
    "### Comment it, if training the network for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.Saver().restore(sess,'trained_params/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs=450\n",
    "no_of_batches=int(X_data_train.shape[0]/batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for _ in range(no_of_batches):\n",
    "        sess.run(train_step)\n",
    "    print(epoch,'completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check  Accuracy on Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summ=0\n",
    "for _ in range(no_of_batches):\n",
    "    summ=summ+sess.run(accuracy)\n",
    "print(summ/no_of_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the threads that were filling the input queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained weights of the network on the disk so that they can be loaded later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.Saver().save(sess,'trained_params/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
